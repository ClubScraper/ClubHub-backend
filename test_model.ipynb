{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created to quickly test the prompts and predictions of the model without fetching data multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from constants import prompt_template\n",
    "import concurrent.futures\n",
    "from supabase import create_client, Client\n",
    "from datetime import datetime, timedelta\n",
    "from huggingface_hub import InferenceClient\n",
    "import instaloader\n",
    "from itertools import dropwhile, takewhile\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNTS_TABLE=\"club_accounts\"\n",
    "DATA_TABLE=\"test\"\n",
    "\n",
    "MODEL=\"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    def __init__(self):\n",
    "        self.db: Client = create_client(os.getenv(\"SUPABASE_URL\"), os.getenv(\"SUPABASE_KEY\"))\n",
    "    \n",
    "        \"\"\"\n",
    "        TO DO! As of right now this function is useless as its functionality \n",
    "        already exists within the Supabase Python client \n",
    "        \"\"\"\n",
    "    def getData(self, table_name, column):      \n",
    "        response = self.db.table(table_name).select(\"*\").execute()\n",
    "        data = [d[column] for d in response.data]\n",
    "        return data\n",
    "\n",
    "        \"\"\"\n",
    "        This function both format and inserts data data to the table table_name. \n",
    "        data is expected to be in json format enclosed within a list.\n",
    "        \"\"\"\n",
    "    def insertData(self, table_name, data):\n",
    "        try:\n",
    "            response = self.db.table(table_name).insert(data).execute()\n",
    "            return response\n",
    "        except Exception as exception:\n",
    "            return exception\n",
    "    \n",
    "        \"\"\"\n",
    "        This function deletes all rows from the specified database whose date \n",
    "        attribute is before the specified date date\n",
    "        \"\"\"\n",
    "    def purgeData(self, table_name, date):\n",
    "        response = self.db.table(table_name).delete().lt(\"date\", date).execute()\n",
    "        try:\n",
    "            return response\n",
    "        except Exception as exception:\n",
    "            return exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    def __init__(self, model, token):\n",
    "        self.model = client = InferenceClient(model, token=token)\n",
    "\n",
    "    def predict_post(self, post):\n",
    "        prompt = prompt_template.format(account=post['account'], \n",
    "                                        date=post['date'], \n",
    "                                        caption=post['caption'])\n",
    "        response = self.model.text_generation(prompt=prompt)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchData(accounts, StartDate, EndDate, L):\n",
    "    data = []\n",
    "  \n",
    "    for account in accounts:\n",
    "        posts = instaloader.Profile.from_username(L.context, account).get_posts()\n",
    "        \n",
    "        filter_after_since = lambda p: p.date > EndDate\n",
    "        filter_until = lambda p: p.date > StartDate\n",
    "        \n",
    "        filtered_posts = takewhile(filter_until, dropwhile(filter_after_since, posts))\n",
    "        \n",
    "        for post in filtered_posts:\n",
    "            data.append({\"account\": account, \n",
    "                         \"date\": post.date.strftime('%Y/%m/%d'), \n",
    "                         \"caption\": post.caption})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import fetchData\n",
    "from database import Database\n",
    "from inference import Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = instaloader.Instaloader()\n",
    "L.load_session_from_file(os.getenv(\"INSTAGRAM_USER\"), os.getenv(\"INSTAGRAM_SESSION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database()\n",
    "LLAMA = Inference(model=MODEL, token=os.getenv(\"HUGGING_FACE_TOKEN\"))\n",
    "start_date = datetime.today() - timedelta(days=7)\n",
    "end_date = datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APIResponse[TypeVar](data=[], count=None)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts = db.getData(ACCOUNTS_TABLE, \"club_name\")\n",
    "purge_date = datetime.today() - timedelta(days=90)\n",
    "db.purgeData(ACCOUNTS_TABLE, purge_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_data = fetchData(accounts, start_date, end_date, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given the following Instagram post data:\n",
    "\n",
    "Account: {account}\n",
    "Date: {date}\n",
    "Caption: {caption}\n",
    "\n",
    "Extract the following information and return it in this format with NO EXPLANATIONS:\n",
    "- Account (as 'account')\n",
    "- Posting Date (as 'posting_date')\n",
    "- Type of post ('Competition', 'Networking', 'Workshop', 'Hiring', or 'Misc.')\n",
    "- Relevant Dates (dates mentioned in the caption, EXCLUDE THE DATE POSTED, MUST BE IN YYYY/MM/DD FORMAT) If there are no relevant dates, put '' \n",
    "\n",
    "Only return the data in the response AS A DICTIONARY. DO NOT INCLUDE ANY EXPLANATIONS, CODE, OR RAW DATA.\n",
    "PLEASE EXCLUDE ANY STATEMENTS SUCH AS \"import re, import json, def extract_info, ''', #, Note: \", etc.\n",
    "\n",
    "Response format: {{\"account\": \"{account}\", \"posting_date\": \"{date}\", \"type\": \"<Type>\", \"relevant_dates\": \"<Relevant Dates>\"}}\n",
    "\n",
    "ONLY OUTPUT THE LIST, NO EXPLANATIONS, # COMMENTS, DUPLICATE DATA, NOTES, OR EXTRA TEXT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "\n",
    "for post in unfiltered_data:\n",
    "    predictions.append(LLAMA.predict_post(post=post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_upload = []\n",
    "pattern = re.compile(r'\\{.*\\}')\n",
    "for prediction in predictions:\n",
    "    match = pattern.search(prediction)\n",
    "    if match:\n",
    "        dict = match.group(0)\n",
    "        result = json.loads(dict)\n",
    "        to_upload.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LLama model and Tuning Parameters (commented out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "#from huggingface_hub import login\n",
    "#login(os.getenv(\"HUGGING_FACE_TOKEN_2\"))\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "#generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "#response = generator(prompt_template, max_length=250, temperature=0.01, top_p=0.85, top_k=1, num_return_sequences=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
